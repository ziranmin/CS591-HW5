{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from translate import Translator\n",
    "import numpy as np\n",
    "import preprocessor as p\n",
    "import re\n",
    "import codecs\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from nltk.stem.snowball import SpanishStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Original Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/ziranmin/Desktop/Assignment5/train/english_train.text\", 'r') as f:\n",
    "    en_train_texts = [l.strip() for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/ziranmin/Desktop/Assignment5/train/english_train.labels', 'r') as f:\n",
    "    en_train_labels = [int(l.strip()) for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/ziranmin/Desktop/Assignment5/train/spanish_train.text\", 'r') as f:\n",
    "    sp_train_texts = [l.strip() for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/ziranmin/Desktop/Assignment5/train/spanish_train.labels', 'r') as f:\n",
    "    sp_train_labels = [int(l.strip()) for l in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Original Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/ziranmin/Desktop/Assignment5/test/english_test.text\", 'r') as f:\n",
    "    en_test_texts = [l.strip() for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/ziranmin/Desktop/Assignment5/test/english_test.labels\", 'r') as f:\n",
    "    en_test_labels = [int(l.strip()) for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/ziranmin/Desktop/Assignment5/test/spanish_test.text\", 'r') as f:\n",
    "    sp_test_texts = [l.strip() for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/ziranmin/Desktop/Assignment5/test/spanish_test.labels\", 'r') as f:\n",
    "    sp_test_labels = [int(l.strip()) for l in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Mapping Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/ziranmin/Desktop/Assignment5/mapping/english_mapping.txt\", 'r') as f:\n",
    "    en_mapping = [l.strip() for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/ziranmin/Desktop/Assignment5/mapping/spanish_mapping.txt\", 'r') as f:\n",
    "    sp_mapping = [l.strip() for l in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ziranmin/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/ziranmin/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweeter preprocessor\n",
    "p.set_options(p.OPT.URL, p.OPT.SMILEY, p.OPT.MENTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare to remove punctuation\n",
    "translator = str.maketrans(\"\", \"\", punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare to get stem words\n",
    "get_stem_en = EnglishStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find All Unusual Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_train_texts_special_char = []\n",
    "for i in range(len(en_train_texts)):\n",
    "    en_train_texts_special_char += re.sub(\"[A-Z]|[À-Ú]|[a-z]|[à-ú]|[0-9]|[' ']\", '', en_train_texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_train_texts_special_char = []\n",
    "for i in range(len(sp_train_texts)):\n",
    "    sp_train_texts_special_char += re.sub(\"[A-Z]|[À-Ú]|[a-z]|[à-ú]|[0-9]|[' ']\", '', sp_train_texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_test_texts_special_char = []\n",
    "for i in range(len(en_test_texts)):\n",
    "    en_test_texts_special_char += re.sub(\"[A-Z]|[À-Ú]|[a-z]|[à-ú]|[0-9]|[' ']\", '', en_test_texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_test_texts_special_char = []\n",
    "for i in range(len(sp_test_texts)):\n",
    "    sp_test_texts_special_char += re.sub(\"[A-Z]|[À-Ú]|[a-z]|[à-ú]|[0-9]|[' ']\", '', sp_test_texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_special_char = np.unique(en_train_texts_special_char + sp_train_texts_special_char + en_test_texts_special_char + sp_test_texts_special_char) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_special_char  = all_special_char.tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_special_char += ['...']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_char_single_string = ''\n",
    "for i in range(len(all_special_char)):\n",
    "    special_char_single_string += all_special_char[i]\n",
    "    \n",
    "special_char_single_string = '[' + special_char_single_string + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\xa0¡£¥¦ª«¯³´·»¿ÜûüĀāăĄćğīİıŃńňōŠżžƈƖơƷƸəɛɢɩɪɬɱɴʀʔʕʻ˃ˈ˘ˢ̵̸̡̨̄͛͟ΑΒΓΔΕΖΘΙΚΛΜΝΞΟΠΡΣΤΦΧΩίεηικνξστυφωϯАБВДЙМНРСХШабвгдеийклмнопрстухцшщьюяєҒғӜأابتحخدرصضعفقكلمنهويِกขคงจชดตทนปพฟมยรลวสหอะัาิีูเแใไๆ็่้๊ခငတပမေ္ၚლᎠᎥᎬᎶᎽᎾᏁᏆ᠌ᴄᴇᴋᴍᴏᴗᴜᴥᴬᴮᴰᴱᴳᴴᴵᴸᴹᴺᴼᴿᵀᵁᵛᵞᶜᶠạởῳ\\u200b\\u200c\\u200d–—―‘’‛“”†•…⁰€⃣℉→↓↠⇤⇥⇨∘∞≫ⓐⓑⓓⓔⓕⓖⓗⓘⓙⓛⓜⓝⓞⓟⓡⓢⓣⓨ└╳■▷▻▽○◌●◕◡◦★☆☇☉☞☡☥☻♔♕♚♡♩♪♫♬♾⚘⚯⛇⛾✓❥➵➶⠀。《》【】いおかがくけこしじすずっでとなにのはばぶぺまみょらりれわんゞアイウェエカクグコサシスゼソタダチッツデトドノハバビフブベペホポマヨラリルレロン・ーヾ㊣一下世並丹亡人仙休力十去品国坐場夏外大好媽子家布帰帶平後所新旅日時朝林森楽死泰浜浴海焼爸甄甜生界番米糖翔芋英茶虚行要角記語谦谷豐轉辺近鋪雪鮮麻鼎가갓고광구국귀그끼남년뉴늘단딸랑램럴론마밤방버범별북븐비빠사상세셀소수스아야어얼엄에여열오요욕용운워웬음이인일자장재제지천친카켓타탄탔토페포피하한할해행\\uf3e0\\uf8ff︎️！）ＡＥＬＭＮＲＳＴＵＶＷａｂｃｄｅｆｇｈｉｌｍｎｏｐｒｓｔｕｖｗｙ￣�𗀛𝑒𝒶𝒸𝒽𝒾𝓂𝓇𝓈𝓉🄲🄴🄻🄽🅃🅇🅐🅑🅓🅔🅗🅙🅛🅞🅢🅣🅤🅩🇦🇪🇱🇵🇷🇸🇹🇺🕆🕇🕪🖒🖓🛇\\U000fe4e6\\U000fe4eb...]'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_char_single_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean English Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_english(texts):\n",
    "    result = []\n",
    "    for text in texts:\n",
    "        #remove URL links, Smiley, and @user\n",
    "        text = p.clean(text)\n",
    "        #remove special characters\n",
    "        text = re.sub(special_char_single_string, '', text)\n",
    "        #make everything lower case\n",
    "        text = text.lower()\n",
    "        #remove stopwords\n",
    "        text = ' '.join([i for i in text.split() if i not in (stopwords.words('english'))])\n",
    "        #remove punctuation\n",
    "        text = text.translate(translator)\n",
    "        #change every word to stem word\n",
    "        text = [get_stem_en.stem(i) for i  in word_tokenize(text)]\n",
    "        result.append(' '.join(text))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_train_texts_cleaned = clean_english(en_train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_train_texts_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_test_texts_cleaned = clean_english(en_test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_test_texts_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(\"en_train_texts_cleaned.txt\",'w',\"utf-8\") as out_fs:\n",
    "    for each in en_train_texts_cleaned:\n",
    "        out_fs.write(each + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(\"en_test_texts_cleaned.txt\",'w',\"utf-8\") as out_fs:\n",
    "    for each in en_test_texts_cleaned:\n",
    "        out_fs.write(each + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Spanish Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stem_sp = SpanishStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_spanish(texts):\n",
    "    result = []\n",
    "    \n",
    "    for text in texts:\n",
    "        #remove URL links, Smiley, and @user\n",
    "        text = p.clean(text)\n",
    "        #remove special characters\n",
    "        text = re.sub(special_char_single_string, '', text)\n",
    "        #make everything lower case\n",
    "        text = text.lower()\n",
    "        #remove stopwords\n",
    "        text = ' '.join([i for i in text.split() if i not in (stopwords.words('spanish'))])\n",
    "        #remove punctuation\n",
    "        text = text.translate(translator)\n",
    "        #change every word to stem word\n",
    "        text = [get_stem_sp.stem(i) for i  in word_tokenize(text)]\n",
    "        result.append(' '.join(text))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_train_texts_cleaned = clean_spanish(sp_train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sp_train_texts_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_test_texts_cleaned = clean_spanish(sp_test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_test_texts_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(\"sp_train_texts_cleaned.txt\",'w',\"utf-8\") as out_fs:\n",
    "    for each in sp_train_texts_cleaned:\n",
    "        out_fs.write(each + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(\"sp_test_texts_cleaned.txt\",'w',\"utf-8\") as out_fs:\n",
    "    for each in sp_test_texts_cleaned:\n",
    "        out_fs.write(each + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English Tweet Prediction \n",
    "# TF-IDF Vectorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/ziranmin/Desktop/Assignment5/en_train_texts_cleaned.txt\", 'r') as f:\n",
    "    en_train_texts_cleaned_read = [l.strip() for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/ziranmin/Desktop/Assignment5/en_test_texts_cleaned.txt\", 'r') as f:\n",
    "    en_test_texts_cleaned_read = [l.strip() for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_train_tf = tf.fit_transform(en_train_texts_cleaned_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_test_tf = tf.transform(en_test_texts_cleaned_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.fit(en_train_tf, en_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_pred = LR.predict(en_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('predicted_labels_file.txt', en_pred, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('gold_labels_file.txt', np.array(en_test_labels), fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F-Score (official): 19.835\n",
      "-----\n",
      "Micro F-Score: 32.56\n",
      "Precision: 32.56\n",
      "Recall: 32.56\n"
     ]
    }
   ],
   "source": [
    "%run scorer_semeval18.py gold_labels_file.txt predicted_labels_file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(en_train_tf, en_train_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_pred = clf.predict(en_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F-Score (official): 16.864\n",
      "-----\n",
      "Micro F-Score: 26.98\n",
      "Precision: 26.98\n",
      "Recall: 26.98\n"
     ]
    }
   ],
   "source": [
    "np.savetxt('predicted_labels_file.txt', en_pred, fmt='%d')\n",
    "np.savetxt('gold_labels_file.txt', np.array(en_test_labels), fmt='%d')\n",
    "%run scorer_semeval18.py gold_labels_file.txt predicted_labels_file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Different Parameters for Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:  0.001\n",
      "Macro F-Score (official): 1.79\n",
      "-----\n",
      "Micro F-Score: 21.8\n",
      "Precision: 21.8\n",
      "Recall: 21.8\n",
      "\n",
      "C:  0.01\n",
      "Macro F-Score (official): 1.912\n",
      "-----\n",
      "Micro F-Score: 21.81\n",
      "Precision: 21.81\n",
      "Recall: 21.81\n",
      "\n",
      "C:  0.1\n",
      "Macro F-Score (official): 12.669\n",
      "-----\n",
      "Micro F-Score: 28.74\n",
      "Precision: 28.74\n",
      "Recall: 28.74\n",
      "\n",
      "C:  1\n",
      "Macro F-Score (official): 19.835\n",
      "-----\n",
      "Micro F-Score: 32.56\n",
      "Precision: 32.56\n",
      "Recall: 32.56\n",
      "\n",
      "C:  2\n",
      "Macro F-Score (official): 20.898\n",
      "-----\n",
      "Micro F-Score: 32.71\n",
      "Precision: 32.71\n",
      "Recall: 32.71\n",
      "\n",
      "C:  3\n",
      "Macro F-Score (official): 21.348\n",
      "-----\n",
      "Micro F-Score: 32.16\n",
      "Precision: 32.16\n",
      "Recall: 32.16\n",
      "\n",
      "C:  4\n",
      "Macro F-Score (official): 21.559\n",
      "-----\n",
      "Micro F-Score: 31.81\n",
      "Precision: 31.81\n",
      "Recall: 31.81\n",
      "\n",
      "C:  5\n",
      "Macro F-Score (official): 21.507\n",
      "-----\n",
      "Micro F-Score: 31.49\n",
      "Precision: 31.49\n",
      "Recall: 31.49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in [0.001, 0.01, 0.1, 1, 2, 3, 4, 5]:\n",
    "    print(\"C: \" , c )\n",
    "    LR = LogisticRegression(C=c)\n",
    "    LR.fit(en_train_tf, en_train_labels)\n",
    "    \n",
    "    en_pred = LR.predict(en_test_tf)\n",
    "    \n",
    "    np.savetxt('predicted_labels_file.txt', en_pred, fmt='%d')\n",
    "    np.savetxt('gold_labels_file.txt', np.array(en_test_labels), fmt='%d')\n",
    "    %run scorer_semeval18.py gold_labels_file.txt predicted_labels_file.txt\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spanish Tweet Prediction \n",
    "# TF-IDF Vectorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/ziranmin/Desktop/Assignment5/sp_train_texts_cleaned.txt\", 'r') as f:\n",
    "    sp_train_texts_cleaned_read = [l.strip() for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/ziranmin/Desktop/Assignment5/sp_test_texts_cleaned.txt\", 'r') as f:\n",
    "    sp_test_texts_cleaned_read = [l.strip() for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_train_tf = tf.fit_transform(sp_train_texts_cleaned_read)\n",
    "sp_test_tf = tf.transform(sp_test_texts_cleaned_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F-Score (official): 8.319\n",
      "-----\n",
      "Micro F-Score: 28.5\n",
      "Precision: 28.5\n",
      "Recall: 28.5\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(sp_train_tf, sp_train_labels)\n",
    "    \n",
    "sp_pred = LR.predict(sp_test_tf)\n",
    "    \n",
    "np.savetxt('predicted_labels_file.txt', sp_pred, fmt='%d')\n",
    "np.savetxt('gold_labels_file.txt', np.array(sp_test_labels), fmt='%d')\n",
    "%run scorer_semeval18.py gold_labels_file.txt predicted_labels_file.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:  1\n",
      "Macro F-Score (official): 8.319\n",
      "-----\n",
      "Micro F-Score: 28.5\n",
      "Precision: 28.5\n",
      "Recall: 28.5\n",
      "\n",
      "C:  2\n",
      "Macro F-Score (official): 11.44\n",
      "-----\n",
      "Micro F-Score: 29.5\n",
      "Precision: 29.5\n",
      "Recall: 29.5\n",
      "\n",
      "C:  3\n",
      "Macro F-Score (official): 12.087\n",
      "-----\n",
      "Micro F-Score: 29.0\n",
      "Precision: 29.0\n",
      "Recall: 29.0\n",
      "\n",
      "C:  4\n",
      "Macro F-Score (official): 13.119\n",
      "-----\n",
      "Micro F-Score: 29.1\n",
      "Precision: 29.1\n",
      "Recall: 29.1\n",
      "\n",
      "C:  5\n",
      "Macro F-Score (official): 13.591\n",
      "-----\n",
      "Micro F-Score: 28.5\n",
      "Precision: 28.5\n",
      "Recall: 28.5\n",
      "\n",
      "C:  6\n",
      "Macro F-Score (official): 13.497\n",
      "-----\n",
      "Micro F-Score: 28.1\n",
      "Precision: 28.1\n",
      "Recall: 28.1\n",
      "\n",
      "C:  7\n",
      "Macro F-Score (official): 13.417\n",
      "-----\n",
      "Micro F-Score: 27.7\n",
      "Precision: 27.7\n",
      "Recall: 27.7\n",
      "\n",
      "C:  8\n",
      "Macro F-Score (official): 13.119\n",
      "-----\n",
      "Micro F-Score: 27.2\n",
      "Precision: 27.2\n",
      "Recall: 27.2\n",
      "\n",
      "C:  9\n",
      "Macro F-Score (official): 13.025\n",
      "-----\n",
      "Micro F-Score: 26.9\n",
      "Precision: 26.9\n",
      "Recall: 26.9\n",
      "\n",
      "C:  10\n",
      "Macro F-Score (official): 12.982\n",
      "-----\n",
      "Micro F-Score: 26.8\n",
      "Precision: 26.8\n",
      "Recall: 26.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in range(1,11):\n",
    "    print(\"C: \" , c )\n",
    "    LR = LogisticRegression(C=c)\n",
    "    LR.fit(sp_train_tf, sp_train_labels)\n",
    "    \n",
    "    sp_pred = LR.predict(sp_test_tf)\n",
    "    \n",
    "    np.savetxt('predicted_labels_file.txt', sp_pred, fmt='%d')\n",
    "    np.savetxt('gold_labels_file.txt', np.array(sp_test_labels), fmt='%d')\n",
    "    %run scorer_semeval18.py gold_labels_file.txt predicted_labels_file.txt\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(sp_train_tf, sp_train_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_pred = clf.predict(sp_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F-Score (official): 11.06\n",
      "-----\n",
      "Micro F-Score: 23.6\n",
      "Precision: 23.6\n",
      "Recall: 23.6\n"
     ]
    }
   ],
   "source": [
    "np.savetxt('predicted_labels_file.txt', sp_pred, fmt='%d')\n",
    "np.savetxt('gold_labels_file.txt', np.array(sp_test_labels), fmt='%s')\n",
    "%run scorer_semeval18.py gold_labels_file.txt predicted_labels_file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English Tweet Prediction\n",
    "# Word2Vec Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'GoogleNews-vectors-negative300.bin'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziranmin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "words = list(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_train_tokenize = []\n",
    "all_read = en_train_texts_cleaned_read + en_test_texts_cleaned_read\n",
    "for i in range(len(all_read)):\n",
    "    en_train_tokenize += [word_tokenize(all_read[i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_train_tokenize_model = Word2Vec(en_train_tokenize, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(en_train_tokenize_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93385"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziranmin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "en_train_embeded = []\n",
    "for i in en_train_texts_cleaned_read:\n",
    "    temp = np.zeros(100)\n",
    "    n = 0 \n",
    "    for j in i.split():\n",
    "        if j in words:\n",
    "            temp += en_train_tokenize_model[j]\n",
    "            n += 1\n",
    "    if n != 0:\n",
    "        temp /= n\n",
    "    en_train_embeded.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziranmin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "en_test_embeded = []\n",
    "for i in en_test_texts_cleaned_read:\n",
    "    temp = np.zeros(100)\n",
    "    n = 0 \n",
    "    for j in i.split():\n",
    "        if j in words:\n",
    "            temp += en_train_tokenize_model[j]\n",
    "            n += 1\n",
    "    if n != 0:\n",
    "        temp /= n\n",
    "    en_test_embeded.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(en_train_embeded, en_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_pred = LR.predict(en_test_embeded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F-Score (official): 11.132\n",
      "-----\n",
      "Micro F-Score: 26.77\n",
      "Precision: 26.77\n",
      "Recall: 26.77\n"
     ]
    }
   ],
   "source": [
    "np.savetxt('predicted_labels_file.txt', en_pred, fmt='%d')\n",
    "np.savetxt('gold_labels_file.txt', np.array(en_test_labels), fmt='%d')\n",
    "%run scorer_semeval18.py gold_labels_file.txt predicted_labels_file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(en_train_embeded, en_train_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_pred = clf.predict(en_test_embeded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F-Score (official): 11.09\n",
      "-----\n",
      "Micro F-Score: 21.61\n",
      "Precision: 21.61\n",
      "Recall: 21.61\n"
     ]
    }
   ],
   "source": [
    "np.savetxt('predicted_labels_file.txt', en_pred, fmt='%d')\n",
    "np.savetxt('gold_labels_file.txt', np.array(en_test_labels), fmt='%s')\n",
    "%run scorer_semeval18.py gold_labels_file.txt predicted_labels_file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English Tweet Prediction\n",
    "# Word2Vec Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_train_tokenize = []\n",
    "all_read_sp = sp_train_texts_cleaned_read + sp_test_texts_cleaned_read\n",
    "for i in range(len(all_read_sp)):\n",
    "    sp_train_tokenize += [word_tokenize(all_read_sp[i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_train_tokenize_model = Word2Vec(sp_train_tokenize, min_count=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_words = list(sp_train_tokenize_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (ignore the following output for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziranmin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225\n",
      "450\n",
      "675\n",
      "900\n",
      "1125\n",
      "1350\n",
      "1575\n",
      "1800\n",
      "2025\n",
      "2250\n",
      "2475\n",
      "2700\n",
      "2925\n",
      "3150\n",
      "3375\n",
      "3600\n",
      "3825\n",
      "4050\n",
      "4275\n",
      "4500\n",
      "4725\n",
      "4950\n",
      "5175\n",
      "5400\n",
      "5625\n",
      "5850\n",
      "6075\n",
      "6300\n",
      "6525\n",
      "6750\n",
      "6975\n",
      "7200\n",
      "7425\n",
      "7650\n",
      "7875\n",
      "8100\n",
      "8325\n",
      "8550\n",
      "8775\n",
      "9000\n",
      "9225\n",
      "9450\n",
      "9675\n",
      "9900\n",
      "10125\n",
      "10350\n",
      "10575\n",
      "10800\n",
      "11025\n",
      "11250\n",
      "11475\n",
      "11700\n",
      "11925\n",
      "12150\n",
      "12375\n",
      "12600\n",
      "12825\n",
      "13050\n",
      "13275\n",
      "13500\n",
      "13725\n",
      "13950\n",
      "14175\n",
      "14400\n",
      "14625\n",
      "14850\n",
      "15075\n",
      "15300\n",
      "15525\n",
      "15750\n",
      "15975\n",
      "16200\n",
      "16425\n",
      "16650\n",
      "16875\n",
      "17100\n",
      "17325\n",
      "17550\n",
      "17775\n",
      "18000\n",
      "18225\n",
      "18450\n",
      "18675\n",
      "18900\n"
     ]
    }
   ],
   "source": [
    "sp_train_embeded = []\n",
    "for i in sp_train_texts_cleaned_read:\n",
    "    temp = np.zeros(100)\n",
    "    n = 0 \n",
    "    for j in i.split():\n",
    "        if j in sp_words:\n",
    "            temp += sp_train_tokenize_model[j]\n",
    "            n += 1\n",
    "    if n != 0:\n",
    "        temp /= n\n",
    "    sp_train_embeded.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziranmin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "sp_test_embeded = []\n",
    "for i in sp_test_texts_cleaned_read:\n",
    "    temp = np.zeros(100)\n",
    "    n = 0 \n",
    "    for j in i.split():\n",
    "        if j in sp_words:\n",
    "            temp += sp_train_tokenize_model[j]\n",
    "            n += 1\n",
    "    if n != 0:\n",
    "        temp /= n\n",
    "    sp_test_embeded.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F-Score (official): 2.849\n",
      "-----\n",
      "Micro F-Score: 20.9\n",
      "Precision: 20.9\n",
      "Recall: 20.9\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(sp_train_embeded, sp_train_labels)\n",
    "\n",
    "sp_pred = LR.predict(sp_test_embeded)\n",
    "\n",
    "\n",
    "np.savetxt('predicted_labels_file.txt', sp_pred, fmt='%d')\n",
    "np.savetxt('gold_labels_file.txt', np.array(sp_test_labels), fmt='%s')\n",
    "%run scorer_semeval18.py gold_labels_file.txt predicted_labels_file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F-Score (official): 5.366\n",
      "-----\n",
      "Micro F-Score: 14.4\n",
      "Precision: 14.4\n",
      "Recall: 14.4\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(sp_train_embeded, sp_train_labels) \n",
    "sp_pred = clf.predict(sp_test_embeded)\n",
    "np.savetxt('predicted_labels_file.txt', sp_pred, fmt='%d')\n",
    "np.savetxt('gold_labels_file.txt', np.array(sp_test_labels), fmt='%s')\n",
    "%run scorer_semeval18.py gold_labels_file.txt predicted_labels_file.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
