{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from translate import Translator\n",
    "import numpy as np\n",
    "import preprocessor as p\n",
    "import re\n",
    "import codecs\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from nltk.stem.snowball import SpanishStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Original Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/ziranmin/Desktop/Assignment5/train/english_train.text\", 'r') as f:\n",
    "    en_train_texts = [l.strip() for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/ziranmin/Desktop/Assignment5/train/english_train.labels', 'r') as f:\n",
    "    en_train_labels = [int(l.strip()) for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/ziranmin/Desktop/Assignment5/train/spanish_train.text\", 'r') as f:\n",
    "    sp_train_texts = [l.strip() for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/ziranmin/Desktop/Assignment5/train/spanish_train.labels', 'r') as f:\n",
    "    sp_train_labels = [int(l.strip()) for l in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Original Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/ziranmin/Desktop/Assignment5/test/english_test.text\", 'r') as f:\n",
    "    en_test_texts = [l.strip() for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/ziranmin/Desktop/Assignment5/test/english_test.labels\", 'r') as f:\n",
    "    en_test_labels = [int(l.strip()) for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/ziranmin/Desktop/Assignment5/test/spanish_test.text\", 'r') as f:\n",
    "    sp_test_texts = [l.strip() for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/ziranmin/Desktop/Assignment5/test/spanish_test.labels\", 'r') as f:\n",
    "    sp_test_labels = [int(l.strip()) for l in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Mapping Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/ziranmin/Desktop/Assignment5/mapping/english_mapping.txt\", 'r') as f:\n",
    "    en_mapping = [l.strip() for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/ziranmin/Desktop/Assignment5/mapping/spanish_mapping.txt\", 'r') as f:\n",
    "    sp_mapping = [l.strip() for l in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ziranmin/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/ziranmin/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweeter preprocessor\n",
    "p.set_options(p.OPT.URL, p.OPT.SMILEY, p.OPT.MENTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare to remove punctuation\n",
    "translator = str.maketrans(\"\", \"\", punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare to get stem words\n",
    "get_stem_en = EnglishStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find All Unusual Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_train_texts_special_char = []\n",
    "for i in range(len(en_train_texts)):\n",
    "    en_train_texts_special_char += re.sub(\"[A-Z]|[Ã€-Ãš]|[a-z]|[Ã -Ãº]|[0-9]|[' ']\", '', en_train_texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_train_texts_special_char = []\n",
    "for i in range(len(sp_train_texts)):\n",
    "    sp_train_texts_special_char += re.sub(\"[A-Z]|[Ã€-Ãš]|[a-z]|[Ã -Ãº]|[0-9]|[' ']\", '', sp_train_texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_test_texts_special_char = []\n",
    "for i in range(len(en_test_texts)):\n",
    "    en_test_texts_special_char += re.sub(\"[A-Z]|[Ã€-Ãš]|[a-z]|[Ã -Ãº]|[0-9]|[' ']\", '', en_test_texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_test_texts_special_char = []\n",
    "for i in range(len(sp_test_texts)):\n",
    "    sp_test_texts_special_char += re.sub(\"[A-Z]|[Ã€-Ãš]|[a-z]|[Ã -Ãº]|[0-9]|[' ']\", '', sp_test_texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_special_char = np.unique(en_train_texts_special_char + sp_train_texts_special_char + en_test_texts_special_char + sp_test_texts_special_char) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_special_char  = all_special_char.tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_special_char += ['...']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_char_single_string = ''\n",
    "for i in range(len(all_special_char)):\n",
    "    special_char_single_string += all_special_char[i]\n",
    "    \n",
    "special_char_single_string = '[' + special_char_single_string + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\xa0Â¡Â£Â¥Â¦ÂªÂ«Â¯Â³Â´Â·Â»Â¿ÃœÃ»Ã¼Ä€ÄÄƒÄ„Ä‡ÄŸÄ«Ä°Ä±ÅƒÅ„ÅˆÅÅ Å¼Å¾ÆˆÆ–Æ¡Æ·Æ¸É™É›É¢É©ÉªÉ¬É±É´Ê€Ê”Ê•Ê»ËƒËˆË˜Ë¢ÌµÌ¸Ì¡Ì¨Ì„Í›ÍŸÎ‘Î’Î“Î”Î•Î–Î˜Î™ÎšÎ›ÎœÎÎÎŸÎ Î¡Î£Î¤Î¦Î§Î©Î¯ÎµÎ·Î¹ÎºÎ½Î¾ÏƒÏ„Ï…Ï†Ï‰Ï¯ĞĞ‘Ğ’Ğ”Ğ™ĞœĞĞ Ğ¡Ğ¥Ğ¨Ğ°Ğ±Ğ²Ğ³Ğ´ĞµĞ¸Ğ¹ĞºĞ»Ğ¼Ğ½Ğ¾Ğ¿Ñ€ÑÑ‚ÑƒÑ…Ñ†ÑˆÑ‰ÑŒÑÑÑ”Ò’Ò“ÓœØ£Ø§Ø¨ØªØ­Ø®Ø¯Ø±ØµØ¶Ø¹ÙÙ‚ÙƒÙ„Ù…Ù†Ù‡ÙˆÙŠÙà¸à¸‚à¸„à¸‡à¸ˆà¸Šà¸”à¸•à¸—à¸™à¸›à¸à¸Ÿà¸¡à¸¢à¸£à¸¥à¸§à¸ªà¸«à¸­à¸°à¸±à¸²à¸´à¸µà¸¹à¹€à¹à¹ƒà¹„à¹†à¹‡à¹ˆà¹‰à¹Šá€á€„á€á€•á€™á€±á€¹ášáƒšá á¥á¬á¶á½á¾áá†á Œá´„á´‡á´‹á´á´á´—á´œá´¥á´¬á´®á´°á´±á´³á´´á´µá´¸á´¹á´ºá´¼á´¿áµ€áµáµ›áµá¶œá¶ áº¡á»Ÿá¿³\\u200b\\u200c\\u200dâ€“â€”â€•â€˜â€™â€›â€œâ€â€ â€¢â€¦â°â‚¬âƒ£â„‰â†’â†“â† â‡¤â‡¥â‡¨âˆ˜âˆâ‰«â“â“‘â““â“”â“•â“–â“—â“˜â“™â“›â“œâ“â“â“Ÿâ“¡â“¢â“£â“¨â””â•³â– â–·â–»â–½â—‹â—Œâ—â—•â—¡â—¦â˜…â˜†â˜‡â˜‰â˜â˜¡â˜¥â˜»â™”â™•â™šâ™¡â™©â™ªâ™«â™¬â™¾âš˜âš¯â›‡â›¾âœ“â¥âµâ¶â €ã€‚ã€Šã€‹ã€ã€‘ã„ãŠã‹ãŒãã‘ã“ã—ã˜ã™ãšã£ã§ã¨ãªã«ã®ã¯ã°ã¶ãºã¾ã¿ã‚‡ã‚‰ã‚Šã‚Œã‚ã‚“ã‚ã‚¢ã‚¤ã‚¦ã‚§ã‚¨ã‚«ã‚¯ã‚°ã‚³ã‚µã‚·ã‚¹ã‚¼ã‚½ã‚¿ãƒ€ãƒãƒƒãƒ„ãƒ‡ãƒˆãƒ‰ãƒãƒãƒãƒ“ãƒ•ãƒ–ãƒ™ãƒšãƒ›ãƒãƒãƒ¨ãƒ©ãƒªãƒ«ãƒ¬ãƒ­ãƒ³ãƒ»ãƒ¼ãƒ¾ãŠ£ä¸€ä¸‹ä¸–ä¸¦ä¸¹äº¡äººä»™ä¼‘åŠ›åå»å“å›½åå ´å¤å¤–å¤§å¥½åª½å­å®¶å¸ƒå¸°å¸¶å¹³å¾Œæ‰€æ–°æ—…æ—¥æ™‚æœæ—æ£®æ¥½æ­»æ³°æµœæµ´æµ·ç„¼çˆ¸ç”„ç”œç”Ÿç•Œç•ªç±³ç³–ç¿”èŠ‹è‹±èŒ¶è™šè¡Œè¦è§’è¨˜èªè°¦è°·è±è½‰è¾ºè¿‘é‹ªé›ªé®®éº»é¼ê°€ê°“ê³ ê´‘êµ¬êµ­ê·€ê·¸ë¼ë‚¨ë…„ë‰´ëŠ˜ë‹¨ë”¸ë‘ë¨ëŸ´ë¡ ë§ˆë°¤ë°©ë²„ë²”ë³„ë¶ë¸ë¹„ë¹ ì‚¬ìƒì„¸ì…€ì†Œìˆ˜ìŠ¤ì•„ì•¼ì–´ì–¼ì—„ì—ì—¬ì—´ì˜¤ìš”ìš•ìš©ìš´ì›Œì›¬ìŒì´ì¸ì¼ìì¥ì¬ì œì§€ì²œì¹œì¹´ì¼“íƒ€íƒ„íƒ”í† í˜í¬í”¼í•˜í•œí• í•´í–‰\\uf3e0\\uf8ffï¸ï¸ï¼ï¼‰ï¼¡ï¼¥ï¼¬ï¼­ï¼®ï¼²ï¼³ï¼´ï¼µï¼¶ï¼·ï½ï½‚ï½ƒï½„ï½…ï½†ï½‡ï½ˆï½‰ï½Œï½ï½ï½ï½ï½’ï½“ï½”ï½•ï½–ï½—ï½™ï¿£ï¿½ğ—€›ğ‘’ğ’¶ğ’¸ğ’½ğ’¾ğ“‚ğ“‡ğ“ˆğ“‰ğŸ„²ğŸ„´ğŸ„»ğŸ„½ğŸ…ƒğŸ…‡ğŸ…ğŸ…‘ğŸ…“ğŸ…”ğŸ…—ğŸ…™ğŸ…›ğŸ…ğŸ…¢ğŸ…£ğŸ…¤ğŸ…©ğŸ‡¦ğŸ‡ªğŸ‡±ğŸ‡µğŸ‡·ğŸ‡¸ğŸ‡¹ğŸ‡ºğŸ•†ğŸ•‡ğŸ•ªğŸ–’ğŸ–“ğŸ›‡\\U000fe4e6\\U000fe4eb...]'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_char_single_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean English Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_english(texts):\n",
    "    result = []\n",
    "    for text in texts:\n",
    "        #remove URL links, Smiley, and @user\n",
    "        text = p.clean(text)\n",
    "        #remove special characters\n",
    "        text = re.sub(special_char_single_string, '', text)\n",
    "        #make everything lower case\n",
    "        text = text.lower()\n",
    "        #remove stopwords\n",
    "        text = ' '.join([i for i in text.split() if i not in (stopwords.words('english'))])\n",
    "        #remove punctuation\n",
    "        text = text.translate(translator)\n",
    "        #change every word to stem word\n",
    "        text = [get_stem_en.stem(i) for i  in word_tokenize(text)]\n",
    "        result.append(' '.join(text))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_train_texts_cleaned = clean_english(en_train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_train_texts_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_test_texts_cleaned = clean_english(en_test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_test_texts_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(\"en_train_texts_cleaned.txt\",'w',\"utf-8\") as out_fs:\n",
    "    for each in en_train_texts_cleaned:\n",
    "        out_fs.write(each + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(\"en_test_texts_cleaned.txt\",'w',\"utf-8\") as out_fs:\n",
    "    for each in en_test_texts_cleaned:\n",
    "        out_fs.write(each + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Spanish Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stem_sp = SpanishStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_spanish(texts):\n",
    "    result = []\n",
    "    \n",
    "    for text in texts:\n",
    "        #remove URL links, Smiley, and @user\n",
    "        text = p.clean(text)\n",
    "        #remove special characters\n",
    "        text = re.sub(special_char_single_string, '', text)\n",
    "        #make everything lower case\n",
    "        text = text.lower()\n",
    "        #remove stopwords\n",
    "        text = ' '.join([i for i in text.split() if i not in (stopwords.words('spanish'))])\n",
    "        #remove punctuation\n",
    "        text = text.translate(translator)\n",
    "        #change every word to stem word\n",
    "        text = [get_stem_sp.stem(i) for i  in word_tokenize(text)]\n",
    "        result.append(' '.join(text))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_train_texts_cleaned = clean_spanish(sp_train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sp_train_texts_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_test_texts_cleaned = clean_spanish(sp_test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_test_texts_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(\"sp_train_texts_cleaned.txt\",'w',\"utf-8\") as out_fs:\n",
    "    for each in sp_train_texts_cleaned:\n",
    "        out_fs.write(each + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(\"sp_test_texts_cleaned.txt\",'w',\"utf-8\") as out_fs:\n",
    "    for each in sp_test_texts_cleaned:\n",
    "        out_fs.write(each + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English Tweet Prediction \n",
    "# TF-IDF Vectorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/ziranmin/Desktop/Assignment5/en_train_texts_cleaned.txt\", 'r') as f:\n",
    "    en_train_texts_cleaned_read = [l.strip() for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/ziranmin/Desktop/Assignment5/en_test_texts_cleaned.txt\", 'r') as f:\n",
    "    en_test_texts_cleaned_read = [l.strip() for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_train_tf = tf.fit_transform(en_train_texts_cleaned_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_test_tf = tf.transform(en_test_texts_cleaned_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.fit(en_train_tf, en_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_pred = LR.predict(en_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('predicted_labels_file.txt', en_pred, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('gold_labels_file.txt', np.array(en_test_labels), fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F-Score (official): 19.835\n",
      "-----\n",
      "Micro F-Score: 32.56\n",
      "Precision: 32.56\n",
      "Recall: 32.56\n"
     ]
    }
   ],
   "source": [
    "%run scorer_semeval18.py gold_labels_file.txt predicted_labels_file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(en_train_tf, en_train_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_pred = clf.predict(en_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F-Score (official): 16.864\n",
      "-----\n",
      "Micro F-Score: 26.98\n",
      "Precision: 26.98\n",
      "Recall: 26.98\n"
     ]
    }
   ],
   "source": [
    "np.savetxt('predicted_labels_file.txt', en_pred, fmt='%d')\n",
    "np.savetxt('gold_labels_file.txt', np.array(en_test_labels), fmt='%d')\n",
    "%run scorer_semeval18.py gold_labels_file.txt predicted_labels_file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Different Parameters for Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:  0.001\n",
      "Macro F-Score (official): 1.79\n",
      "-----\n",
      "Micro F-Score: 21.8\n",
      "Precision: 21.8\n",
      "Recall: 21.8\n",
      "\n",
      "C:  0.01\n",
      "Macro F-Score (official): 1.912\n",
      "-----\n",
      "Micro F-Score: 21.81\n",
      "Precision: 21.81\n",
      "Recall: 21.81\n",
      "\n",
      "C:  0.1\n",
      "Macro F-Score (official): 12.669\n",
      "-----\n",
      "Micro F-Score: 28.74\n",
      "Precision: 28.74\n",
      "Recall: 28.74\n",
      "\n",
      "C:  1\n",
      "Macro F-Score (official): 19.835\n",
      "-----\n",
      "Micro F-Score: 32.56\n",
      "Precision: 32.56\n",
      "Recall: 32.56\n",
      "\n",
      "C:  2\n",
      "Macro F-Score (official): 20.898\n",
      "-----\n",
      "Micro F-Score: 32.71\n",
      "Precision: 32.71\n",
      "Recall: 32.71\n",
      "\n",
      "C:  3\n",
      "Macro F-Score (official): 21.348\n",
      "-----\n",
      "Micro F-Score: 32.16\n",
      "Precision: 32.16\n",
      "Recall: 32.16\n",
      "\n",
      "C:  4\n",
      "Macro F-Score (official): 21.559\n",
      "-----\n",
      "Micro F-Score: 31.81\n",
      "Precision: 31.81\n",
      "Recall: 31.81\n",
      "\n",
      "C:  5\n",
      "Macro F-Score (official): 21.507\n",
      "-----\n",
      "Micro F-Score: 31.49\n",
      "Precision: 31.49\n",
      "Recall: 31.49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in [0.001, 0.01, 0.1, 1, 2, 3, 4, 5]:\n",
    "    print(\"C: \" , c )\n",
    "    LR = LogisticRegression(C=c)\n",
    "    LR.fit(en_train_tf, en_train_labels)\n",
    "    \n",
    "    en_pred = LR.predict(en_test_tf)\n",
    "    \n",
    "    np.savetxt('predicted_labels_file.txt', en_pred, fmt='%d')\n",
    "    np.savetxt('gold_labels_file.txt', np.array(en_test_labels), fmt='%d')\n",
    "    %run scorer_semeval18.py gold_labels_file.txt predicted_labels_file.txt\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spanish Tweet Prediction \n",
    "# TF-IDF Vectorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/ziranmin/Desktop/Assignment5/sp_train_texts_cleaned.txt\", 'r') as f:\n",
    "    sp_train_texts_cleaned_read = [l.strip() for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/ziranmin/Desktop/Assignment5/sp_test_texts_cleaned.txt\", 'r') as f:\n",
    "    sp_test_texts_cleaned_read = [l.strip() for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_train_tf = tf.fit_transform(sp_train_texts_cleaned_read)\n",
    "sp_test_tf = tf.transform(sp_test_texts_cleaned_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F-Score (official): 8.319\n",
      "-----\n",
      "Micro F-Score: 28.5\n",
      "Precision: 28.5\n",
      "Recall: 28.5\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(sp_train_tf, sp_train_labels)\n",
    "    \n",
    "sp_pred = LR.predict(sp_test_tf)\n",
    "    \n",
    "np.savetxt('predicted_labels_file.txt', sp_pred, fmt='%d')\n",
    "np.savetxt('gold_labels_file.txt', np.array(sp_test_labels), fmt='%d')\n",
    "%run scorer_semeval18.py gold_labels_file.txt predicted_labels_file.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:  1\n",
      "Macro F-Score (official): 8.319\n",
      "-----\n",
      "Micro F-Score: 28.5\n",
      "Precision: 28.5\n",
      "Recall: 28.5\n",
      "\n",
      "C:  2\n",
      "Macro F-Score (official): 11.44\n",
      "-----\n",
      "Micro F-Score: 29.5\n",
      "Precision: 29.5\n",
      "Recall: 29.5\n",
      "\n",
      "C:  3\n",
      "Macro F-Score (official): 12.087\n",
      "-----\n",
      "Micro F-Score: 29.0\n",
      "Precision: 29.0\n",
      "Recall: 29.0\n",
      "\n",
      "C:  4\n",
      "Macro F-Score (official): 13.119\n",
      "-----\n",
      "Micro F-Score: 29.1\n",
      "Precision: 29.1\n",
      "Recall: 29.1\n",
      "\n",
      "C:  5\n",
      "Macro F-Score (official): 13.591\n",
      "-----\n",
      "Micro F-Score: 28.5\n",
      "Precision: 28.5\n",
      "Recall: 28.5\n",
      "\n",
      "C:  6\n",
      "Macro F-Score (official): 13.497\n",
      "-----\n",
      "Micro F-Score: 28.1\n",
      "Precision: 28.1\n",
      "Recall: 28.1\n",
      "\n",
      "C:  7\n",
      "Macro F-Score (official): 13.417\n",
      "-----\n",
      "Micro F-Score: 27.7\n",
      "Precision: 27.7\n",
      "Recall: 27.7\n",
      "\n",
      "C:  8\n",
      "Macro F-Score (official): 13.119\n",
      "-----\n",
      "Micro F-Score: 27.2\n",
      "Precision: 27.2\n",
      "Recall: 27.2\n",
      "\n",
      "C:  9\n",
      "Macro F-Score (official): 13.025\n",
      "-----\n",
      "Micro F-Score: 26.9\n",
      "Precision: 26.9\n",
      "Recall: 26.9\n",
      "\n",
      "C:  10\n",
      "Macro F-Score (official): 12.982\n",
      "-----\n",
      "Micro F-Score: 26.8\n",
      "Precision: 26.8\n",
      "Recall: 26.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in range(1,11):\n",
    "    print(\"C: \" , c )\n",
    "    LR = LogisticRegression(C=c)\n",
    "    LR.fit(sp_train_tf, sp_train_labels)\n",
    "    \n",
    "    sp_pred = LR.predict(sp_test_tf)\n",
    "    \n",
    "    np.savetxt('predicted_labels_file.txt', sp_pred, fmt='%d')\n",
    "    np.savetxt('gold_labels_file.txt', np.array(sp_test_labels), fmt='%d')\n",
    "    %run scorer_semeval18.py gold_labels_file.txt predicted_labels_file.txt\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(sp_train_tf, sp_train_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_pred = clf.predict(sp_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F-Score (official): 11.06\n",
      "-----\n",
      "Micro F-Score: 23.6\n",
      "Precision: 23.6\n",
      "Recall: 23.6\n"
     ]
    }
   ],
   "source": [
    "np.savetxt('predicted_labels_file.txt', sp_pred, fmt='%d')\n",
    "np.savetxt('gold_labels_file.txt', np.array(sp_test_labels), fmt='%s')\n",
    "%run scorer_semeval18.py gold_labels_file.txt predicted_labels_file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English Tweet Prediction\n",
    "# Word2Vec Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'GoogleNews-vectors-negative300.bin'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziranmin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "words = list(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_train_tokenize = []\n",
    "all_read = en_train_texts_cleaned_read + en_test_texts_cleaned_read\n",
    "for i in range(len(all_read)):\n",
    "    en_train_tokenize += [word_tokenize(all_read[i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_train_tokenize_model = Word2Vec(en_train_tokenize, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(en_train_tokenize_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93385"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziranmin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "en_train_embeded = []\n",
    "for i in en_train_texts_cleaned_read:\n",
    "    temp = np.zeros(100)\n",
    "    n = 0 \n",
    "    for j in i.split():\n",
    "        if j in words:\n",
    "            temp += en_train_tokenize_model[j]\n",
    "            n += 1\n",
    "    if n != 0:\n",
    "        temp /= n\n",
    "    en_train_embeded.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziranmin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "en_test_embeded = []\n",
    "for i in en_test_texts_cleaned_read:\n",
    "    temp = np.zeros(100)\n",
    "    n = 0 \n",
    "    for j in i.split():\n",
    "        if j in words:\n",
    "            temp += en_train_tokenize_model[j]\n",
    "            n += 1\n",
    "    if n != 0:\n",
    "        temp /= n\n",
    "    en_test_embeded.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(en_train_embeded, en_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_pred = LR.predict(en_test_embeded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F-Score (official): 11.132\n",
      "-----\n",
      "Micro F-Score: 26.77\n",
      "Precision: 26.77\n",
      "Recall: 26.77\n"
     ]
    }
   ],
   "source": [
    "np.savetxt('predicted_labels_file.txt', en_pred, fmt='%d')\n",
    "np.savetxt('gold_labels_file.txt', np.array(en_test_labels), fmt='%d')\n",
    "%run scorer_semeval18.py gold_labels_file.txt predicted_labels_file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(en_train_embeded, en_train_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_pred = clf.predict(en_test_embeded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F-Score (official): 11.09\n",
      "-----\n",
      "Micro F-Score: 21.61\n",
      "Precision: 21.61\n",
      "Recall: 21.61\n"
     ]
    }
   ],
   "source": [
    "np.savetxt('predicted_labels_file.txt', en_pred, fmt='%d')\n",
    "np.savetxt('gold_labels_file.txt', np.array(en_test_labels), fmt='%s')\n",
    "%run scorer_semeval18.py gold_labels_file.txt predicted_labels_file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English Tweet Prediction\n",
    "# Word2Vec Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_train_tokenize = []\n",
    "all_read_sp = sp_train_texts_cleaned_read + sp_test_texts_cleaned_read\n",
    "for i in range(len(all_read_sp)):\n",
    "    sp_train_tokenize += [word_tokenize(all_read_sp[i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_train_tokenize_model = Word2Vec(sp_train_tokenize, min_count=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_words = list(sp_train_tokenize_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (ignore the following output for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziranmin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225\n",
      "450\n",
      "675\n",
      "900\n",
      "1125\n",
      "1350\n",
      "1575\n",
      "1800\n",
      "2025\n",
      "2250\n",
      "2475\n",
      "2700\n",
      "2925\n",
      "3150\n",
      "3375\n",
      "3600\n",
      "3825\n",
      "4050\n",
      "4275\n",
      "4500\n",
      "4725\n",
      "4950\n",
      "5175\n",
      "5400\n",
      "5625\n",
      "5850\n",
      "6075\n",
      "6300\n",
      "6525\n",
      "6750\n",
      "6975\n",
      "7200\n",
      "7425\n",
      "7650\n",
      "7875\n",
      "8100\n",
      "8325\n",
      "8550\n",
      "8775\n",
      "9000\n",
      "9225\n",
      "9450\n",
      "9675\n",
      "9900\n",
      "10125\n",
      "10350\n",
      "10575\n",
      "10800\n",
      "11025\n",
      "11250\n",
      "11475\n",
      "11700\n",
      "11925\n",
      "12150\n",
      "12375\n",
      "12600\n",
      "12825\n",
      "13050\n",
      "13275\n",
      "13500\n",
      "13725\n",
      "13950\n",
      "14175\n",
      "14400\n",
      "14625\n",
      "14850\n",
      "15075\n",
      "15300\n",
      "15525\n",
      "15750\n",
      "15975\n",
      "16200\n",
      "16425\n",
      "16650\n",
      "16875\n",
      "17100\n",
      "17325\n",
      "17550\n",
      "17775\n",
      "18000\n",
      "18225\n",
      "18450\n",
      "18675\n",
      "18900\n"
     ]
    }
   ],
   "source": [
    "sp_train_embeded = []\n",
    "for i in sp_train_texts_cleaned_read:\n",
    "    temp = np.zeros(100)\n",
    "    n = 0 \n",
    "    for j in i.split():\n",
    "        if j in sp_words:\n",
    "            temp += sp_train_tokenize_model[j]\n",
    "            n += 1\n",
    "    if n != 0:\n",
    "        temp /= n\n",
    "    sp_train_embeded.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziranmin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "sp_test_embeded = []\n",
    "for i in sp_test_texts_cleaned_read:\n",
    "    temp = np.zeros(100)\n",
    "    n = 0 \n",
    "    for j in i.split():\n",
    "        if j in sp_words:\n",
    "            temp += sp_train_tokenize_model[j]\n",
    "            n += 1\n",
    "    if n != 0:\n",
    "        temp /= n\n",
    "    sp_test_embeded.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F-Score (official): 2.849\n",
      "-----\n",
      "Micro F-Score: 20.9\n",
      "Precision: 20.9\n",
      "Recall: 20.9\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(sp_train_embeded, sp_train_labels)\n",
    "\n",
    "sp_pred = LR.predict(sp_test_embeded)\n",
    "\n",
    "\n",
    "np.savetxt('predicted_labels_file.txt', sp_pred, fmt='%d')\n",
    "np.savetxt('gold_labels_file.txt', np.array(sp_test_labels), fmt='%s')\n",
    "%run scorer_semeval18.py gold_labels_file.txt predicted_labels_file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F-Score (official): 5.366\n",
      "-----\n",
      "Micro F-Score: 14.4\n",
      "Precision: 14.4\n",
      "Recall: 14.4\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(sp_train_embeded, sp_train_labels) \n",
    "sp_pred = clf.predict(sp_test_embeded)\n",
    "np.savetxt('predicted_labels_file.txt', sp_pred, fmt='%d')\n",
    "np.savetxt('gold_labels_file.txt', np.array(sp_test_labels), fmt='%s')\n",
    "%run scorer_semeval18.py gold_labels_file.txt predicted_labels_file.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
